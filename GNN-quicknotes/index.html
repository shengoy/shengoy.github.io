<!DOCTYPE html><html><head><meta charset=UTF-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=0"><title>GNN quicknotes | magmell</title><meta name=author content=magmell><meta name=copyright content=magmell><link rel="shortcut icon" href=http://magmell.site/img/My.jpg><meta name=keywords content=GNN><meta name=description content="本篇为最近看的两篇1,2 GNN Introduction 的笔记。 Challenges 机器学习的输入通常为网格状数组，即矩阵。而图（Graph not Image）的信息比较复杂，结点、边、全局信息、连通性这些难以表达。 排列不变性（Node-Order Equivariance）。通过置换同一个图的的结点顺序会得到不同的邻接矩阵，这显然是不符合排列不变性的要求的。 扩展性（Scalabil"><meta property=og:type content=article><meta property=og:title content="GNN quicknotes"><meta property=og:url content=http://magmell.site/GNN-quicknotes/ ><meta property=og:site_name content=magmell><meta property=og:description content="本篇为最近看的两篇1,2 GNN Introduction 的笔记。 Challenges 机器学习的输入通常为网格状数组，即矩阵。而图（Graph not Image）的信息比较复杂，结点、边、全局信息、连通性这些难以表达。 排列不变性（Node-Order Equivariance）。通过置换同一个图的的结点顺序会得到不同的邻接矩阵，这显然是不符合排列不变性的要求的。 扩展性（Scalabil"><meta property=og:locale><meta property=og:image content=http://magmell.site/img/My.jpg><meta property=article:published_time content=2022-03-20T08:45:01.000Z><meta property=article:modified_time content=2022-03-29T08:31:52.000Z><meta property=article:author content=magmell><meta property=article:tag content=GNN><meta name=twitter:card content=summary><meta name=twitter:image content=http://magmell.site/img/My.jpg><meta http-equiv=Cache-Control content=no-siteapp><link href=//cdn.jsdelivr.net rel=preconnect><link href=http://magmell.site rel=prefetch><link href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css rel=stylesheet><link href=/css/main.css rel=stylesheet><script src=/js/utlis.js>"use strict";</script><meta name=generator content="Hexo 5.4.1"></head><body><script>"use strict";var $config={tocStyle:"visible",CDN:{fancyboxJs:"https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js",fancyboxCss:"https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css"},searchFile:"/search.xml",codeBlockExpand:{enable:!0,height:400,scrollTop:200}};</script><script>"use strict";var _hmt=_hmt||[];!function(){var t=document.createElement("script"),e=(t.src="https://hm.baidu.com/hm.js?b8312b70c827f3279376517c136f52f5",document.getElementsByTagName("script")[0]);e.parentNode.insertBefore(t,e)}();</script><script>"use strict";var script=document.createElement("script");function gtag(){dataLayer.push(arguments)}script.src="https://www.googletagmanager.com/gtag/js?id=G-DHWF0JVX7P",script.async=!0,document.head.appendChild(script),window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-DHWF0JVX7P");</script><script>"use strict";document.addEventListener("pjax:complete",function(){"undefined"!=typeof _hmt&&"function"==typeof _hmt.push&&_hmt.push(["_trackPageview",window.location.pathname]),"function"==typeof ga&&ga("send","pageview",window.location.href),"function"==typeof gtag&&gtag("event","pageview",{page_location:window.location.href})});</script><div id=body-wrap><nav id=nav-wrap><div class=navbar><div class=bar><a href=/ class=title>magmell</a> <i class="fas fa-search search-btn"></i><ul class=menu><li><a href=/ >首页</a></li><li><a class=menu-child-hover href=javascript:void(0);>找文章</a><ul class=menu-child><li><a href=/tags>标签</a></li><li><a href=/categories>分类</a></li><li><a href=/archives>归档</a></li></ul></li><li><a href=/about>关于我</a></li></ul><i class="fas fa-bars open-nav"></i></div></div><div id=mobile-nav><ul><li><a href=/ >首页</a></li><li><a href=/tags>标签</a></li><li><a href=/categories>分类</a></li><li><a href=/archives>归档</a></li><li><a href=/about>关于我</a></li></ul></div></nav><main id=main><article id=post><div class=post-info><div class=post-title><h1>GNN quicknotes</h1></div><div class=post-meta><div class=post-date><i class="far fa-calendar-alt fa-fw post-meta-icon"></i> <span class=post-meta-label>发表于 2022-03-20 | </span><i class="fas fa-history fa-fw post-meta-icon"></i> <span class=post-meta-label>更新于 2024-04-20</span></div><div class=post-meta-wordcount><i class="far fa-file-word fa-fw post-meta-icon"></i> <span class=post-meta-label>总字数:</span> <span class=word-count>921 | </span><i class="far fa-clock fa-fw post-meta-icon"></i> <span class=post-meta-label>阅读时长:</span> <span>3分钟</span> | <i class="far fa-eye fa-fw post-meta-icon"></i> <span id=/GNN-quicknotes/ class=leancloud_visitors data-flag-title="GNN quicknotes"><span class=post-meta-label>阅读量:</span> <span class=leancloud-visitors-count>0</span></span></div></div></div><div class=post-content><p>本篇为最近看的两篇<a href=#refer-anchor-1,#refer-anchor-2><sup>1,2</sup></a> GNN Introduction 的笔记。</p><h3 id=Challenges><a href=#Challenges class=headerlink title=Challenges></a>Challenges</h3><ol><li>机器学习的输入通常为网格状数组，即矩阵。而图（Graph not Image）的信息比较复杂，结点、边、全局信息、连通性这些难以表达。</li><li>排列不变性（Node-Order Equivariance）。通过置换同一个图的的结点顺序会得到不同的邻接矩阵，这显然是不符合排列不变性的要求的。</li><li>扩展性（Scalability）。不同图的量级相差极大，简单如无机分子图，只有几个原子结点；复杂的如社交网络图，可能拥有超过十亿的用户结点。</li></ol><h3 id=What><a href=#What class=headerlink title=What></a>What</h3><p>步骤</p><ol><li>聚合邻居特征</li><li>与自身特征结合</li></ol><p>本质上，消息传递和卷积都是通过聚合和处理元素邻居的信息来更新元素值的操作。说人话就是图中结点是根据与它有边相连的结点的信息来更新的。根据结点、边之间的交互总共有四种消息传递方式，主要是结点-结点的方式。消息传递方式有个缺陷：距离远的结点之间无法交流信息，解决方案</p><ol><li>全部结点间可以交流信息（注意力机制），但是计算量大。</li><li>使用全图表示，添加一个连接所有结点的虚拟结点。</li></ol><h3 id=Performance><a href=#Performance class=headerlink title=Performance></a>Performance</h3><p>如何获得更好的性能</p><ol><li>参数量，一般来说正相关</li><li>embedding dim，维度越高，平均性能越高，偏差越小</li><li>layers，深度越深，平均越好，但也可能会有所下降</li><li>聚合函数，影响不大？</li><li>消息传递方式，边、结点、全局信息</li></ol><h4 id=Where><a href=#Where class=headerlink title=Where></a>Where</h4><p>背景及起源</p><h4 id=ChebNet><a href=#ChebNet class=headerlink title=ChebNet></a>ChebNet</h4><h3 id=Improve><a href=#Improve class=headerlink title=Improve></a>Improve</h3><p>改进方向</p><ol><li>更复杂的图算法，之前的都是基于邻域的pooling操作，很多图的概念无法表达，比如路径。</li><li>图本身，更好的去表示图，利用更多的结构和关系。</li></ol><h3 id=sample><a href=#sample class=headerlink title=sample></a>sample</h3><p>图采样，图中不同结点的边数量会变，整张图做一个batch可能会导致内存不足，如何得到图的batch是一个难点。</p><p>一个解决方案：subgraph，随机选一个结点，扩展到它的k阶邻居，选取一个固定大小的node set。</p><h3 id=Others><a href=#Others class=headerlink title=Others></a>Others</h3><p>一些其他概念</p><h4 id=Inductive-bias><a href=#Inductive-bias class=headerlink title="Inductive bias"></a>Inductive bias</h4><p>先验知识，对特定的图，可以利用一些辅助信息提高性能</p><h4 id=Aggregation><a href=#Aggregation class=headerlink title=Aggregation></a>Aggregation</h4><ol><li><strong>mean</strong>：邻居偏差大或者需要标准化特征</li><li><strong>max</strong>：需要显著特征</li><li><strong>sum</strong>：前两者一个平衡</li></ol><p>经过K层后，一个结点的表示可以看作一个k阶邻居构成的子图表示，但是直接列举这些子图代价昂贵。</p><p>图上的卷积操作可以用邻接矩阵和特征矩阵的相乘实现</p><h4 id=Graph-Dual><a href=#Graph-Dual class=headerlink title="Graph Dual"></a>Graph Dual</h4><p>图上的边看成结点，结点看成边，则可以把一个边预测问题转变为结点预测问题。</p><h4 id=Generative-model><a href=#Generative-model class=headerlink title="Generative model"></a>Generative model</h4><p>生成新图，比如制药中找新的药物分子图。图变分自编码器。</p><h4 id=Spectral><a href=#Spectral class=headerlink title=Spectral></a>Spectral</h4><p>谱表示可以保存大部分特征，即可以用较少的参数量得到相当的性能。</p><ul><li>较小特征值对应的特征向量对应于低频分量，偏向全局表征，越smooth</li><li>较大特征值对应的特征向量对应与高频分量，偏向局部表征</li></ul><p>图（graph）上的谱域卷积可以看作image上频域卷积的泛化</p><p>缺点：</p><ul><li>需要计算特征向量U，时间复杂度较高</li><li>有重复的U和U’相乘计算</li><li>只针对某个图，换个图拉普拉斯矩阵不一样</li></ul><h3 id=参考><a href=#参考 class=headerlink title=参考></a>参考</h3><div id=refer-anchor-1></div><ul><li>[1] <a target=_blank rel=noopener href=https://distill.pub/2021/understanding-gnns/ >Understanding Convolutions on Graphs (distill.pub)</a></li></ul><div id=refer-anchor-2></div><ul><li>[2] <a target=_blank rel=noopener href=https://distill.pub/2021/gnn-intro/ >A Gentle Introduction to Graph Neural Networks (distill.pub)</a></li></ul></div><div class=post-copyright><div class=post-copyright-icon></div><div class=post-copyright-author><span class=post-copyright-meta>文章作者: </span><span class=post-copyright-info><a href=mailto:shengouy@stu.xmu.edu.cn>shoy</a></span></div><div class=post-copyright-type><span class=post-copyright-meta>文章链接: </span><span class=post-copyright-info><a href=http://magmell.site/GNN-quicknotes/ >http://magmell.site/GNN-quicknotes/</a></span></div><div class=post-copyright-notice><span class=post-copyright-meta>版权声明: </span><span class=post-copyright-info>本博客所有文章除特别声明外，均采用 <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/ target=_blank>CC BY-NC-SA 4.0 </a>许可协议。转载请注明来自 <a href=http://magmell.site/GNN-quicknotes/ target=_blank>blog from magmell</a> ！</span></div></div><div class=post-tag><span><i class="fa fa-tag"></i> <a href=tags/GNN/ ><span>GNN</span></a></span></div><div class=pagination-post><a href=/%E6%BE%A1%E5%A0%82%E9%9B%86/ ><div class=prev-title><i class="fas fa-chevron-left"></i>澡堂集</div><div class=prev-desc>南方人刚开始来帝都上学面对公共澡堂还是有点不知所措的（才没有，老夫高中就是大澡堂子hhh），慢慢地也就适应了，而且相对于独立卫浴大澡堂也别有一番趣味。本篇记录一些澡堂的发生的小故事（内容纯属瞎编...</div></a><a href=/%E3%80%8E%E5%B0%B1%E7%AE%97%E7%9C%8B%E4%B8%8D%E8%A7%81%E6%9C%AA%E6%9D%A5%EF%BC%8C%E6%AD%A4%E6%97%B6%E6%AD%A4%E5%88%BB%E7%9A%84%E5%85%89%E8%BE%89%E3%80%8FS-%E3%80%8A%E6%9C%AB%E6%97%A5%E4%B8%89%E9%97%AE%E3%80%8B/ ><div class=next-title>『就算看不见未来，此时此刻的光辉』S ——《末日三问》<i class="fas fa-chevron-right"></i></div><div class=next-desc>本篇为《末日三问》系列第二篇，因为写着写着发现想写的有点多，全放在一起不太好，打算分成几个短篇。 《末日三问》系列： 『就算看不见未来，此时此刻的光辉』——《末日三问》 本文含有大量剧透，包...</div></a></div><div class=comment-head id=直达评论><hr><div class=comment-headline><i class="fas fa-comments fa-fw"></i> <span>评论</span></div><div id=vcomments></div><script>"use strict";function LoadValine(){getScript("https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js",function(){var e={el:"#vcomments",path:window.location.pathname,appId:"uYPQylOCyVdXUjwoeA1Qlo9r-gzGzoHsz",appKey:"fhFK17SLElipGtq3bmkD9AGi",master:"",friends:"",placeholder:"快来评论吧!!",avatar:"",meta:"nick,mail,link".split(","),pageSize:5,lang:"zh-CN",emojiCDN:"",emojiMaps:null,enableQQ:!0,visitor:!0};new Valine(e)})}LoadValine();</script></div></article><div id=toc-wrap><div id=toc><div class=toc-title><div>目录 <span class=num>0%</span></div><progress class=progress value=0 max=100></progress></div><div class=toc-list><ol class=toc><li class="toc-item toc-level-3"><a class=toc-link href=#Challenges><span class=toc-text>Challenges</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#What><span class=toc-text>What</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#Performance><span class=toc-text>Performance</span></a><ol class=toc-child><li class="toc-item toc-level-4"><a class=toc-link href=#Where><span class=toc-text>Where</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#ChebNet><span class=toc-text>ChebNet</span></a></li></ol></li><li class="toc-item toc-level-3"><a class=toc-link href=#Improve><span class=toc-text>Improve</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#sample><span class=toc-text>sample</span></a></li><li class="toc-item toc-level-3"><a class=toc-link href=#Others><span class=toc-text>Others</span></a><ol class=toc-child><li class="toc-item toc-level-4"><a class=toc-link href=#Inductive-bias><span class=toc-text>Inductive bias</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#Aggregation><span class=toc-text>Aggregation</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#Graph-Dual><span class=toc-text>Graph Dual</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#Generative-model><span class=toc-text>Generative model</span></a></li><li class="toc-item toc-level-4"><a class=toc-link href=#Spectral><span class=toc-text>Spectral</span></a></li></ol></li><li class="toc-item toc-level-3"><a class=toc-link href=#%E5%8F%82%E8%80%83><span class=toc-text>参考</span></a></li></ol></div></div></div></main><section id=rightside><div class=rightside-btn><a harf=javascript: id=darkmode title=深色/浅色><i class="fas fa-moon"></i></a></div><div class=rightside-item><a harf=javascript: id=darkmode title=深色/浅色><i class="fas fa-moon"></i> </a><a href=javascript: id=settings title=设置><i class="fas fa-cog fa-spin"></i> </a><a id=open-toc title=目录><i class="fas fa-list-ul"></i> </a><a href=javascript:(0) id=darkmode title="深色/浅色 "><i class="fas fa-moon"></i> </a><a href=#直达评论 title=直达评论><i class="fas fa-comments"></i> </a><a href=# title=回到顶部><i class="fas fa-arrow-up"></i></a></div></section><footer class=footer id=footer><div class=copyright>&copy; 2022 - 2024 <i class="fas fa-fan"></i> magmell</div><div class=framework-info><span>框架 </span><a href=https://hexo.io target=_blank>Hexo</a> <span class=footer-separator>|</span> <span>主题 </span><a href=https://github.com/lete114/hexo-theme-MengD target=_blank>MengD.(萌典)</a></div></footer></div><div id=mask onclick='"use strict";closeAll();'></div><div id=local-search><div id=local-search-title>本地搜索</div><input id=local-search-input autocomplete=off placeholder=搜索文章 type=text><hr><div id=local-search-result></div><span class=search-close-button><i class="fas fa-times"></i></span></div><script src=/js/search.js>"use strict";</script><div class=script><script src=/js/main.js>"use strict";</script><script src=/js/lazyload.js>"use strict";</script><script src=/MathJax.js>"use strict";</script><script>"use strict";function LoadPjax(){new Pjax({selectors:["head title",'head meta[name="keywords"]','head meta[name="description"]',"main","#rightside"],cache:!0,cacheBust:!1})}getScript("https://cdn.jsdelivr.net/npm/pjax/pjax.min.js",LoadPjax);var timer=null;function ProgressStart(){var t=10,e=document.createElement("div");e.className="pjax-progress",document.body.prepend(e);clearInterval(timer),timer=setInterval(function(){var e=parseInt(7*Math.random());t+=e+3,document.getElementsByClassName("pjax-progress")[0].style.width=t+"%",95<t&&(t=95)},500)}function ProgressFinish(){clearInterval(timer);var e=document.getElementsByClassName("pjax-progress");e[0].style.width="100%",timer=setTimeout(function(){e[0].parentNode.removeChild(e[0])},700)}document.addEventListener("pjax:send",function(){ProgressStart()}),document.addEventListener("pjax:complete",function(){ProgressFinish(),exeAllFn(),ImgLazyLoad("body img[data-img]","data-img"),document.querySelectorAll("script[data-pjax]").forEach(function(e){var t=document.createElement("script"),a=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach(function(e){return t.setAttribute(e.name,e.value)}),t.appendChild(document.createTextNode(a)),e.parentNode.replaceChild(t,e)})}),document.addEventListener("pjax:error",function(e){404===e.request.status&&pjax.loadUrl("/404.html")});</script></div></body><body><script src=/live2d/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05>"use strict";</script><script>"use strict";L2Dwidget.init({pluginRootPath:"live2d/",pluginJsPath:"lib/",pluginModelPath:"assets/",tagMode:!1,debug:!1,model:{jsonPath:"/live2d/assets/chtholly.model.json"},display:{position:"left",width:200,height:400,hOffset:-30,vOffset:-55},mobile:{show:!0,scale:.4},react:{opacity:.7},log:!1});</script></body></html>